import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
import faiss
import pickle
import numpy as np
import time
from pathlib import Path

# --- í™˜ê²½ì„¤ì • ë° API í´ë¼ì´ì–¸íŠ¸ ìƒì„± ---
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ë²¡í„° DBì™€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_resource(show_spinner=False)
def load_vector_db():
    try:
        with open("vectors.pkl", "rb") as f:
            data = pickle.load(f)
        texts = data["texts"]
        vectors = data["vectors"]
        # faissëŠ” read_indexê°€ ì•„ë‹ˆë¼ pickleë¡œ ë¡œë“œ
        with open("faiss_index.pkl", "rb") as f_idx:
            index, _ = pickle.load(f_idx)
        return texts, vectors, index
    except Exception as e:
        st.error(f"ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None, None

texts, vectors, index = load_vector_db()

# --- ì§ˆë¬¸ ë‹µë³€ í•¨ìˆ˜ ---
def ask_question(query: str, level: str = "ì´ˆê¸‰", top_k: int = 3) -> str:
    if not index:
        return "ë²¡í„° DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."

    try:
        embedding_response = client.embeddings.create(
            input=query,
            model="text-embedding-3-small"
        )
        query_vector = np.array(embedding_response.data[0].embedding).astype("float32")
    except Exception as e:
        return f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    D, I = index.search(np.array([query_vector]), top_k)
    context = "\n\n".join([texts[i] for i in I[0]])

    prompt = f"""
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¦ê¶Œ ê¸ˆìœµ êµìœ¡ ì±—ë´‡ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ê´€ë ¨ í•™ìŠµ ìë£Œì…ë‹ˆë‹¤:
{context}

ê¸ˆìœµ ì§€ì‹ ìˆ˜ì¤€: {level}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ì´ ì§ˆë¬¸ì— ëŒ€í•´ {level} ìˆ˜ì¤€ì— ë§ê²Œ ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í•„ìš”í•˜ë©´ ì˜ˆì‹œë„ í¬í•¨í•˜ì„¸ìš”.
"""

    try:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=400
        )
        answer = completion.choices[0].message.content.strip()
    except Exception as e:
        answer = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    return answer

# --- Streamlit UI ---

st.set_page_config(
    page_title="ğŸ’° ëŒ€í•™ìƒ ì¦ê¶Œ ê¸ˆìœµ êµìœ¡ ì±—ë´‡",
    page_icon="ğŸ’¹",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .title-font {
        font-size: 28px !important;
        font-weight: 700 !important;
        color: #0B3D91;
        margin-bottom: 10px;
    }
    .sub-font {
        font-size: 16px !important;
        color: #555555;
        margin-bottom: 20px;
    }
    .chat-box {
        background-color: #f0f4f8;
        padding: 15px;
        border-radius: 12px;
        margin-bottom: 15px;
        box-shadow: 2px 2px 6px rgba(0,0,0,0.1);
    }
    .chat-question {
        font-weight: 600;
        color: #1565c0;
        margin-bottom: 8px;
    }
    .chat-answer {
        white-space: pre-wrap;
        font-size: 15px;
        color: #333333;
    }
    hr {
        margin-top: 30px;
        margin-bottom: 30px;
        border: none;
        border-top: 1px solid #eee;
    }
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”: ì‚¬ìš©ì í”„ë¡œí•„
with st.sidebar:
    st.header("ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì…ë ¥")
    user_level = st.selectbox("ê¸ˆìœµ ì§€ì‹ ìˆ˜ì¤€ ì„ íƒ", ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"])
    user_grade = st.selectbox("í•™ë…„ ì„ íƒ", ["1í•™ë…„", "2í•™ë…„", "3í•™ë…„", "4í•™ë…„", "ê¸°íƒ€"])
    st.markdown("---")
    st.markdown("ë³¸ ì±—ë´‡ì€ ì¦ê¶Œ ê¸ˆìœµ êµìœ¡ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì˜ì—­ ì œëª© ë° ì„¤ëª…
st.markdown('<div class="title-font">ëŒ€í•™ìƒ ì¦ê¶Œ ê¸ˆìœµ êµìœ¡ ì±—ë´‡ (RAG ê¸°ë°˜)</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-font">ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ê¸ˆìœµ ì§€ì‹ ìˆ˜ì¤€ì— ë§ì¶° ì¹œì ˆí•˜ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

# 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ: ì§ˆë¬¸ ì…ë ¥ / ëŒ€í™” ê¸°ë¡
col1, col2 = st.columns([3, 2])

with col1:
    query = st.text_area("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ETFê°€ ë­ì˜ˆìš”?", height=130)
    if st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°"):
        if not query.strip():
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not texts or not index:
            st.error("ì‹œìŠ¤í…œ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                answer = ask_question(query, user_level)
                time.sleep(0.5)
                # ëŒ€í™” ê¸°ë¡ ì €ì¥
                if "history" not in st.session_state:
                    st.session_state.history = []
                st.session_state.history.append({"ì§ˆë¬¸": query, "ë‹µë³€": answer})
                # ì…ë ¥ì°½ ë¹„ìš°ê¸° (UI ì²˜ë¦¬)
                st.experimental_rerun()

with col2:
    st.markdown('<div class="title-font">ğŸ—’ï¸ ëŒ€í™” ê¸°ë¡</div>', unsafe_allow_html=True)
    if "history" in st.session_state and st.session_state.history:
        for i, chat in enumerate(reversed(st.session_state.history)):
            st.markdown(f'''
                <div class="chat-box">
                    <div class="chat-question">Q{i+1}. {chat['ì§ˆë¬¸']}</div>
                    <div class="chat-answer">{chat['ë‹µë³€']}</div>
                </div>
            ''', unsafe_allow_html=True)
    else:
        st.info("ì•„ì§ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì™¼ìª½ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!")

# í‘¸í„°
st.markdown("<hr>", unsafe_allow_html=True)
st.markdown('<p style="font-size:12px; color:#999;">â“’ 2025 ì¦ê¶Œêµìœ¡ AI ì±—ë´‡ í”„ë¡œì íŠ¸</p>', unsafe_allow_html=True)
