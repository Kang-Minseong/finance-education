import os
import pickle
import faiss
import numpy as np
from dotenv import load_dotenv
from openai import OpenAI

# ğŸ”‘ API ë¡œë”©
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ“¦ ë²¡í„° DB ë° ë¬¸ì„œ ë¡œë“œ
with open("faiss_index.pkl", "rb") as f:
    index, documents = pickle.load(f)

# ğŸ“š ì§ˆë¬¸ ìœ í˜• ê°ì§€ í•¨ìˆ˜
def detect_question_type(query: str) -> str:
    if "ì°¨ì´" in query or "ë¹„êµ" in query:
        return "ë¹„êµ"
    elif "ê³„ì‚°" in query or "êµ¬í•˜ëŠ”" in query:
        return "ê³„ì‚°"
    elif "ì˜ˆì‹œ" in query:
        return "ì˜ˆì‹œ"
    else:
        return "ì •ì˜"

# ğŸ§  GPT ì‘ë‹µ í•¨ìˆ˜
def ask_question(query, level="ì¤‘"):
    # 1. ì§ˆë¬¸ ì„ë² ë”©
    embedding_response = client.embeddings.create(
        input=query,
        model="text-embedding-3-small"
    )
    query_vector = np.array(embedding_response.data[0].embedding).astype("float32")

    # 2. FAISS ê²€ìƒ‰
    D, I = index.search(np.array([query_vector]), k=3)
    context = "\n\n".join([documents[i] for i in I[0]])

    # 3. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
    q_type = detect_question_type(query)

    # 4. ë ˆë²¨ë³„ ë§íˆ¬ ë° ì•ˆë‚´ ë¬¸êµ¬
    style_guide = {
        "ì´ˆ": "ì•„ì£¼ ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•˜ê³ , ì¼ìƒì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”.",
        "ì¤‘": "ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•˜ê³ , í•„ìš” ì‹œ ì‚¬ë¡€ë‚˜ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”.",
        "ê³ ": "ì „ë¬¸ ìš©ì–´ì™€ ë°°ê²½ ì§€ì‹ì„ í¬í•¨í•´ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”."
    }

    # 5. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•™ìƒ ëŒ€ìƒì˜ ì¦ê¶Œ ê¸ˆìœµ êµìœ¡ ì±—ë´‡ì…ë‹ˆë‹¤.

ğŸ“˜ [ì‚¬ìš©ì ì •ë³´]
- ì§€ì‹ ìˆ˜ì¤€: {level}
- ì§ˆë¬¸ ìœ í˜•: {q_type}
- ì§ˆë¬¸: {query}

ğŸ“š [ì°¸ê³  í•™ìŠµ ìë£Œ]
{context}

ğŸ’¬ [ë‹µë³€ ê°€ì´ë“œ]
- {q_type} ìœ í˜•ì˜ ì§ˆë¬¸ì— ë§ì¶° ì„¤ëª…
- {style_guide.get(level, 'ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•˜ì„¸ìš”.')}
- í•µì‹¬ ê°œë… â†’ ì˜ˆì‹œ/ì‚¬ë¡€ â†’ í•µì‹¬ ìš”ì•½ ìˆœìœ¼ë¡œ ì„¤ëª…
- ë„ˆë¬´ ì–´ë µê²Œ ì„¤ëª…í•˜ì§€ ë§ê³  ì¹œì ˆí•˜ê²Œ ë§í•´ì¤˜
"""

    # 6. GPT í˜¸ì¶œ
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµêµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )

    return completion.choices[0].message.content.strip()

# ğŸš€ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ“˜ ì¦ê¶Œ êµìœ¡ ì±—ë´‡ì…ë‹ˆë‹¤.")
    level = input("ğŸ‘¤ ê¸ˆìœµ ì§€ì‹ ìˆ˜ì¤€ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì´ˆ/ì¤‘/ê³ ) >>> ").strip()
    while True:
        q = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit') >>> ").strip()
        if q.lower() == "exit":
            break
        answer = ask_question(q, level=level)
        print("\nğŸ’¡ GPT ì‘ë‹µ:\n", answer)
